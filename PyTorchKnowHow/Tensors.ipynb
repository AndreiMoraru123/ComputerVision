{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.25 0.5  0.75 1.  ]\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "n = np.linspace(0,1,5)\n",
    "t = torch.linspace(0,1,5)\n",
    "\n",
    "print(n)\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n",
      "torch.Size([3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "n = np.arange(48).reshape(3,4,4)\n",
    "t = torch.arange(48).reshape(3,4,4)\n",
    "\n",
    "print(n.shape)\n",
    "print(t.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3, 8])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([3,4])\n",
    "\n",
    "a*b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "General Broadcasting Rules\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when\n",
    "\n",
    "they are equal, or\n",
    "one of them is 1\n",
    "Example: The following are compatible\n",
    "\n",
    "Shape 1: (1,6,4,1,7,2)\n",
    "\n",
    "Shape 2: (5,6,1,3,1,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((6,5))\n",
    "b = np.arange(5).reshape((1,5))\n",
    "\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 2, 3, 4]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 2., 3., 4., 5.],\n       [1., 2., 3., 4., 5.],\n       [1., 2., 3., 4., 5.],\n       [1., 2., 3., 4., 5.],\n       [1., 2., 3., 4., 5.],\n       [1., 2., 3., 4., 5.]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 3., 4., 5.],\n        [1., 2., 3., 4., 5.],\n        [1., 2., 3., 4., 5.],\n        [1., 2., 3., 4., 5.],\n        [1., 2., 3., 4., 5.],\n        [1., 2., 3., 4., 5.]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((6,5))\n",
    "b = torch.arange(5).reshape(1,5)\n",
    "\n",
    "a+b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The arrays/tensors don't need to have the same number of dimenions. If one of the arrays/tensors has less dimensions than the other\n",
    "\n",
    "Example: Scaling each other the color channels of an image by a different amount:\n",
    "\n",
    "Image  (3d array): 256 x 256 x 3\n",
    "Scale  (1d array):             3\n",
    "Result (3d array): 256 x 256 x 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.5000, 1.5000, 1.0000],\n         [0.5000, 1.5000, 1.0000]],\n\n        [[0.5000, 1.5000, 1.0000],\n         [0.5000, 1.5000, 1.0000]]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image = torch.ones((2,2,3))\n",
    "Scale = torch.tensor([0.5,1.5,1]) # scalare pentru RGB (compatibilitate de marime)\n",
    "\n",
    "Result = Image * Scale\n",
    "Result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example: One has an array of 2 images and wants to scale the color channels of each image by a slightly different amount:\n",
    "\n",
    "Images  (4d array): 2 x 256 x 256 x 3\n",
    "Scales  (4d array): 2 x 1 x 1 x 3\n",
    "Results  (4d array): 2 x 256 x 256 x 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000]],\n\n         [[0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000]],\n\n         [[0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000]],\n\n         [[0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000],\n          [0.5000, 1.5000, 1.0000]]],\n\n\n        [[[1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000]],\n\n         [[1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000]],\n\n         [[1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000]],\n\n         [[1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000],\n          [1.5000, 1.0000, 0.5000]]]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images = torch.ones((2,4,4,3)) # two 4x4 RGB images\n",
    "Scales = torch.tensor([0.5, 1.5,1,1.5,1,0.5]).reshape(2,1,1,3)\n",
    "\n",
    "Result = Images * Scales\n",
    "\n",
    "Result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Operations Across Dimensions\n",
    "This is so fundamental for pytorch. Obviously simple operations can be done one 1 dimensional tensors:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(2.1250), tensor(1.6520), tensor(4.), tensor(0.5000))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0.5,1,3,4])\n",
    "torch.mean(t), torch.std(t), torch.max(t), torch.min(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "But suppose we have a 2d tensor, for example, and want to compute the mean value of each columns:\n",
    "\n",
    "Note: taking the mean of each column means taking the mean across the rows (which are the first dimension)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.],\n        [16., 17., 18., 19.]], dtype=torch.float64)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(20,dtype=float).reshape(5,4)\n",
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 1., 2., 3.], dtype=torch.float64)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 8.,  9., 10., 11.], dtype=torch.float64)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t, axis=0) # mean across the rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([256, 256, 3])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(5,256,256,3)\n",
    "\n",
    "# Take the mean across the batch (size 5)\n",
    "\n",
    "torch.mean(t,axis=0).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 256, 256])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the mean across the color channels\n",
    "\n",
    "torch.mean(t,axis=-1).shape # average of brightness"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take only the maximum color channel values (and get the corresponding indices):\n",
    "\n",
    "This is done all the time in image segmentation models (i.e. take an image, decide which pixels correspond to, say, a car)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[2, 0, 1,  ..., 1, 1, 2],\n         [1, 0, 2,  ..., 2, 2, 2],\n         [2, 1, 1,  ..., 1, 2, 1],\n         ...,\n         [0, 1, 2,  ..., 1, 1, 1],\n         [2, 1, 2,  ..., 0, 2, 0],\n         [2, 2, 0,  ..., 0, 0, 0]],\n\n        [[0, 2, 0,  ..., 0, 0, 0],\n         [0, 1, 1,  ..., 1, 0, 2],\n         [2, 0, 1,  ..., 0, 1, 0],\n         ...,\n         [2, 2, 0,  ..., 2, 0, 1],\n         [2, 0, 2,  ..., 0, 2, 2],\n         [0, 1, 1,  ..., 1, 0, 0]],\n\n        [[0, 1, 1,  ..., 0, 2, 0],\n         [1, 0, 0,  ..., 1, 1, 1],\n         [1, 2, 2,  ..., 2, 1, 0],\n         ...,\n         [0, 0, 0,  ..., 1, 0, 0],\n         [0, 1, 2,  ..., 1, 0, 0],\n         [2, 1, 1,  ..., 1, 1, 1]],\n\n        [[1, 1, 2,  ..., 0, 0, 1],\n         [2, 2, 0,  ..., 2, 1, 1],\n         [0, 2, 1,  ..., 2, 0, 2],\n         ...,\n         [1, 2, 0,  ..., 2, 2, 2],\n         [0, 2, 0,  ..., 1, 1, 2],\n         [0, 2, 0,  ..., 1, 0, 0]],\n\n        [[1, 2, 1,  ..., 0, 0, 2],\n         [0, 1, 2,  ..., 2, 0, 0],\n         [2, 0, 2,  ..., 2, 2, 2],\n         ...,\n         [0, 1, 0,  ..., 0, 1, 2],\n         [2, 0, 1,  ..., 1, 2, 1],\n         [2, 1, 2,  ..., 0, 0, 0]]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices = torch.max(t,axis=-1)\n",
    "\n",
    "indices # tells you when red was maximum (e.g. element == 2) or blue, or green"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# So Where Do Pytorch and Numpy Differ?\n",
    "Pytorch starts to really differ from numpy in terms of automatically computing gradients of operations\n",
    "\n",
    "\n",
    "has a gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5., 8.],\n        [4., 6.]], requires_grad=True)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[5.,8.],[4.,6.]], requires_grad=True)\n",
    "\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(917., grad_fn=<SumBackward0>)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.pow(3).sum()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 75., 192.],\n        [ 48., 108.]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the gradient:\n",
    "\n",
    "y.backward() #compute the gradient\n",
    "x.grad #print the gradient (everything that has happened to x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 75., 192.],\n        [ 48., 108.]], grad_fn=<MulBackward0>)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * x**2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The automatic computation of gradients is the backbone of training deep learning models. Unlike in the example above, most gradient computations don't have an analytical formula, so the automatic computation of gradients is essential. In general, if one has\n",
    "\n",
    "Then pytorch can compute\n",
    ". For each of element of the vector\n",
    ". In the context of machine learning,\n",
    " contains all the weights (also known as parameters) of the neural network and  is the Loss Function of the neural network."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additional Benefits\n",
    "In addition, any sort of large matrix multiplication problem is faster with torch tensors than it is with numpy arrays, especially if you're running on a GPU\n",
    "\n",
    "Using torch: (with a CPU. With GPU, this is much much faster)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01982990000396967\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn((1000,1000))\n",
    "B = torch.randn((1000,1000))\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "torch.matmul(A,B)\n",
    "t2 = time.perf_counter()\n",
    "print(t2-t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03208850000373786\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(int(1e6)).reshape((1000,1000))\n",
    "B = np.random.randn(int(1e6)).reshape((1000,1000))\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "A@B\n",
    "t2 = time.perf_counter()\n",
    "print(t2-t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-08-21 21:37:33--  https://raw.githubusercontent.com/lukepolson/youtube_channel/main/Python%20Shorts/crossentropy.ipynb\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 326747 (319K) [text/plain]\n",
      "Saving to: 'crossentropy.ipynb'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 15%  727K 0s\n",
      "    50K .......... .......... .......... .......... .......... 31% 4.61M 0s\n",
      "   100K .......... .......... .......... .......... .......... 47% 1.22M 0s\n",
      "   150K .......... .......... .......... .......... .......... 62% 1.61M 0s\n",
      "   200K .......... .......... .......... .......... .......... 78% 1.61M 0s\n",
      "   250K .......... .......... .......... .......... .......... 94% 8.92M 0s\n",
      "   300K .......... .........                                  100% 7.42M=0.2s\n",
      "\n",
      "2022-08-21 21:37:33 (1.66 MB/s) - 'crossentropy.ipynb' saved [326747/326747]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/lukepolson/youtube_channel/main/Python%20Shorts/crossentropy.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
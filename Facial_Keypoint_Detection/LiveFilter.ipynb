{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n  (conv4): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n  (conv5): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=4608, out_features=1360, bias=True)\n  (fc2): Linear(in_features=1360, out_features=680, bias=True)\n  (drop): Dropout(p=0.8, inplace=False)\n  (fc3): Linear(in_features=680, out_features=136, bias=True)\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary resources\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import Net\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# net = nn.DataParallel(net)\n",
    "\n",
    "## TODO: load the best saved model parameters (by your path name)\n",
    "## You'll need to un-comment the line below and add the correct name for *your* saved model\n",
    "net.load_state_dict(torch.load('saved_models/keypoints_model_1.pt'),strict=False)\n",
    "\n",
    "## print out your net and prepare it for testing (uncomment the line below)\n",
    "net.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sunglasses = cv2.imread('images/sunglasses.png', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('detector_architectures/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_facial_keypoints(image, input_shape):\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    def extract_patch(face):\n",
    "        x, y, w, h = face\n",
    "        patch = gray[y:y+h, x:x+w]\n",
    "        patch = cv2.resize(patch, input_shape)\n",
    "        # patch = np.expand_dims(patch, axis=2)\n",
    "        patch = patch / 255\n",
    "\n",
    "        return patch\n",
    "\n",
    "    def denormalize_keypoints(arg):\n",
    "        face, keypoints = arg\n",
    "        x, y, w, h = face\n",
    "\n",
    "        keypoints_x = keypoints[0::2]\n",
    "        keypoints_y = keypoints[1::2]\n",
    "\n",
    "        keypoints_x = (keypoints_x + 1) * (input_shape[0]//2)\n",
    "        keypoints_y = (keypoints_y + 1) * (input_shape[1]//2)\n",
    "\n",
    "        keypoints_x = (keypoints_x * int(w*0.85) / input_shape[0]) + x\n",
    "        keypoints_y = (keypoints_y * int(h*0.85) / input_shape[1]) + y\n",
    "\n",
    "        keypoints = list(zip(keypoints_x, keypoints_y))\n",
    "\n",
    "        return (face, keypoints)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "\n",
    "    # print(faces.shape)\n",
    "\n",
    "    inputs = np.asarray(list(map(extract_patch, faces)))\n",
    "\n",
    "    inputs = torch.from_numpy(inputs)\n",
    "\n",
    "    inputs = inputs.type(torch.FloatTensor)\n",
    "\n",
    "    inputs.unsqueeze_(1)\n",
    "\n",
    "    if inputs.shape == torch.Size([1, 1, 224, 224]):\n",
    "\n",
    "        predictions = net(inputs)\n",
    "\n",
    "        # predictions = predictions.view(predictions.size()[0], 68, -1)\n",
    "\n",
    "        return list(map(denormalize_keypoints, zip(faces, predictions)))\n",
    "\n",
    "    else:\n",
    "\n",
    "        return list(map(denormalize_keypoints, zip(faces,  torch.zeros([2, 136]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def applyOverlay(background, overlay_rgba):\n",
    "    overlay      = overlay_rgba[:,:,:3]\n",
    "    overlay_mask = overlay_rgba[:,:,3:]\n",
    "\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    background = (background * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay    = (overlay    * (1 / 255.0)) * (overlay_mask    * (1 / 255.0))\n",
    "\n",
    "    return np.uint8(cv2.addWeighted(background, 255.0, overlay, 255.0, 0.0))\n",
    "\n",
    "def applySunglasses(image, facial_keypoints, sunglasses):\n",
    "\n",
    "    image = np.copy(image)\n",
    "    sunglasses = np.copy(sunglasses)\n",
    "\n",
    "    for (face, keypoints) in facial_keypoints:\n",
    "\n",
    "        #Left/right from the subject's perspective\n",
    "        left_eyebrow  = { 'inner': keypoints[27], 'outer': keypoints[34] }\n",
    "        right_eyebrow = { 'inner': keypoints[17], 'outer': keypoints[26] }\n",
    "\n",
    "        # original_height = sunglasses.shape[0]\n",
    "        # original_width  = sunglasses.shape[1]\n",
    "\n",
    "        #When resizing according to eyebrow point,\n",
    "        #The sunglasses are too small and don't look natural.\n",
    "        #This is mitigated by scaling the sunglasses image by 25%\n",
    "        scale_ratio = 0.3\n",
    "\n",
    "        height  = left_eyebrow['inner'][1] - left_eyebrow['outer'][1]\n",
    "        # height = original_height * (width / original_width)\n",
    "\n",
    "        width  = right_eyebrow['inner'][0] - right_eyebrow['outer'][0]\n",
    "\n",
    "        width = np.abs(width.detach().numpy())\n",
    "        height = np.abs(height.detach().numpy())\n",
    "\n",
    "        width = int(width * (1 + scale_ratio))\n",
    "        offset_x = -width * scale_ratio / 2\n",
    "\n",
    "        height = int(height * (1 + scale_ratio))\n",
    "        offset_y = -height * scale_ratio / 2\n",
    "\n",
    "        sunglasses = cv2.resize(sunglasses, (width, height))\n",
    "\n",
    "        x = int(keypoints[17][0] + offset_x)\n",
    "        y = int(keypoints[17][1] + offset_y)\n",
    "\n",
    "        eyes_patch = image[y:y+np.abs(height), x:x+np.abs(width)]\n",
    "        eyes_patch = applyOverlay(eyes_patch, sunglasses)\n",
    "        image[y:y+height, x:x+width] = eyes_patch[:,:,:3]\n",
    "\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def laptop_camera_go():\n",
    "    # Create instance of video capturer\n",
    "    cv2.namedWindow(\"face detection activated\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "\n",
    "    # Try to get the first frame\n",
    "    if vc.isOpened():\n",
    "        rval, frame = vc.read()\n",
    "    else:\n",
    "        rval = False\n",
    "\n",
    "    # keep video stream open\n",
    "    while rval:\n",
    "\n",
    "        sunglasses = cv2.imread('images/sunglasses.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        facial_keypoints = detect_facial_keypoints(frame, input_shape=(224, 224))\n",
    "        frame = applySunglasses(frame, facial_keypoints, sunglasses)\n",
    "\n",
    "        # plot image from camera with detections marked\n",
    "        cv2.imshow(\"face detection activated\", frame)\n",
    "\n",
    "        # exit functionality - press any key to exit laptop video\n",
    "        key = cv2.waitKey(20)\n",
    "        if key > 0: # exit by pressing any key\n",
    "            # destroy windows\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            # hack from stack overflow for making sure window closes on osx --> https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv\n",
    "            for i in range (1,5):\n",
    "                cv2.waitKey(1)\n",
    "            return\n",
    "\n",
    "        # read next frame\n",
    "        time.sleep(0.05)             # control framerate for computation - default 20 frames per sec\n",
    "        rval, frame = vc.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "laptop_camera_go( )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}